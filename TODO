DONE

	Seems like we really need to capture timestamp for portal session update at the time of processing (eg. start of session update), not at the time the portal cruncher processes it

	This way we don't get time stretch and squeeze if the portal cruncher gets overloaded -- the data just comes in a bit late.

	We need a non-paginated way to get set of database relays for "next relays"

	Track number of routes in route matrix via counters sent from leader relay backend

	Track most of relay analysis and relevant data in redis time series.

	Grab key data like, total routes, optimize_ms and stash in admin as time series.

	Display total routes, optimize_ms graphs in admin page in portal

		"route_matrix_total_routes",
		"route_matrix_bytes",
		"route_matrix_optimize_ms",

	Verify route matrix graphs are working in staging

	Verify that we can scale up to 10M sessions, this time redis should not break (25 shards...)

	Seeing some breakage, eg. spaced apart dots, but the data is eventually getting in, and it is not shifted left/right in time.

	Some retries, but not a single fallback to direct as I ramped up past 10M sessions. Fantastic!

	Seems like API crashed during the scale up. Sessions were not viewable for a period. Investigate by looking at api logs...

	When I click on a server @ 10M I don't see any sessions on that server. Is this part broken at scale?

	Relay graphs are fine.

	Admin graphs are fine.

	Map data is fine.

	Check redis cluster loads...

	Check portal cruncher loads

	Check server backend loads

	Check relay backend loads

	Check session cruncher load

	Check server cruncher load
	
TODO

	Check API logs to see why sessions were blind for a minute during ramp up. I suspect a crash...

	I see this:

		Oct 17 16:06:22 api-k6k3 app[1540]: error: got 504 response for http://10.0.0.2/top_servers
		Oct 17 16:06:25 api-k6k3 app[1540]: error: got 504 response for http://10.0.0.4/top_sessions
		Oct 17 16:06:25 api-k6k3 app[1540]: error: got 504 response for http://10.0.0.4/map_data
		Oct 17 16:50:26 api-k6k3 app[1540]: error: failed to get server list: i/o timeout
		Oct 17 16:50:27 api-k6k3 app[1540]: error: failed to get session list: i/o timeout
		Oct 17 16:50:35 api-k6k3 app[1540]: error: failed to get session list: i/o timeout
		Oct 17 16:50:45 api-k6k3 app[1540]: error: failed to get session list: i/o timeout
		Oct 17 16:50:55 api-k6k3 app[1540]: error: failed to get server list: i/o timeout
		Oct 17 16:50:55 api-k6k3 app[1540]: error: failed to get session list: dial tcp 10.0.0.24:11013: i/o timeout
		Oct 17 16:50:55 api-k6k3 app[1540]: error: failed to get session list: dial tcp 10.0.0.24:11013: i/o timeout

	Why would both server list and session list time out? They are totally separate services...

		Oct 17 16:50:40 api-lt9b app[1537]: error: failed to get session list: dial tcp 10.0.0.25:6379: i/o timeout
		Oct 17 16:50:59 api-lt9b app[1537]: error: failed to get session list: dial tcp 10.0.0.24:11013: i/o timeout

	OK it is redis being overloaded primarily, during scale up, but then it normalizes....

	I think the 504 is the session cruncher crashing at some point...

	------------------

	I have disabled all load test sessions

	But I still see 5m sessions in session cruncher, and in portal

	What in the actual fuck is going on?

	------------------

	I'm starting to suspect that the portal cruncher is getting behind at 10M and is a serious problem that needs to be solved.

	The portal cruncher is so backed up, it is still grabbing data from redis for slice data and inserting, and it is making it look like we have ghost sessions... WOW

	------------------

	I had to restart the session cruncher service just to make session counts go back to zero. What the hell could be going on here?

	------------------
	

















































Tasks from load test:

	--------------

	We need to put dependencies on redis, so the redis instances get created first, then all the instance groups do.

	Right now they are created, run without redis, don't work, and I have to deploy a second time when I first bring staging up.

	--------------
	
	There seems to be a load related issue @ 1000 relays.

	--------------

	Fix the fallback to direct when scaling down server backend instances.

	--------------

	Change analytics to perform bulk inserts instead of streaming inserts.

	https://cloud.google.com/bigquery/docs/write-api-batch

	--------------

	Setup projects and service accounts with terraform

	--------------

	Could I be creating too many insertion connections into redis and making it not scale as well as it could? Tuning is probably required here.

	--------------

	Is there something I can do to ensure that all data for a session ends up on the same redis cluster?

	Slice data is what needs to be looked at very closely...

	--------------

	The server sessions not working @ 10M needs to be looked at closely

	It is most likely that too many sessions are locally created per-server, and thus, the overload occurred with the minute, minute - 1 stuff.

	But it is an average of only 100 sessions per-server, which is totally ordinary and to be expected with modern games....

	--------------













Small things:

	--------------

	Still getting some data holes in session slices @ 10M. Which part is getting overloaded? Portal cruncher? Redis?

	--------------

	I would like to see active relay count in time series in admin view

	--------------

	Being able to see portal cruncher processing counts per-second would be useful, this way we can see if the portal cruncher is a bottleneck

	--------------

	Admin message throughput as well would be interesting for sessions

	--------------

	There seems to be rapid leader flapping in relay backend on deploy. You can see this by looking at oscillations in route matrix size and total routes in admin view.

	Maybe modify the code so you cannot be a leader until you have a route matrix with > 0 routes?

	ps. Perhaps less leader flapping, and more -- two instances both think they are the leader. Maybe this was because of the crashing though. Deploy again and see if they flap... ?

	--------------

	The sort order for sessions appears incorrect according to score... not sure why.

	--------------

	Y axis labels spill over the right side when they get up to 100,000, 1,000,000 etc... convert to 500K, 1M, 2M?

	--------------

	Current sessions on server doesn't seem to be correct, or at least, it is 181 when it should be just 1...

	--------------

	uPlot graphs really need to calculate the real maximum from the data passed in

	In so many cases, they fail to calculate it. It's extremely annoying.

	--------------

	I need more space on a standard macbook air screen in the sessions list for longer ISP names

	Right now it is way too tight. A long ISP name would throw the whole layout off

	--------------

	There will be a challenge getting prod relays up in AWS vs. dev. There are no projects to segregate?

	Might need to create a separate project, or distinguish resources with naming convention.

	--------------

	Extend initial delay on server cruncher and session cruncher for 120. This will delay them from becoming active until they have had a full minute + to calculate sessions

	--------------

	Connection type detection needs to be brought back for all platforms in the SDK. On linux, connection type was 0 -> "Unknown"

	--------------

	Session counts on relays being 8 when relay backend restarts seems a bit suspicious. Are we not decrementing session counts somewhere?

	--------------

	Relays need to be setup to use cloud storage for tf state

	--------------

	Probably good to provide a way to disable the high priority threads on server with env var.

	When many server instances are running on one server, this can cause problems. eg. thread starvation

	--------------















Finalize SDK and UE5 plugin:

	------------------

	Update to latest PS4 and PS5 SDK on Windows PC

	Verify that we can build, link and run across PS4

	Verify that we can build, link and run across PS5

	------------------

	Update to latest XDK

	Verify that we can build, link and run across XBoxOne

	Verify that we can build, link and run across SeriesX

	------------------

	Setup PS4 compilation with custom agents

	Setup PS5 compilation with custom agents

	Setup XBoxOne compilation with custom agents

	Setup Series X compilation with custom agents

	------------------

	Get the UE5 plugin back up

	Make sure to include Flush on the server before the server is destroyed

	------------------
